this is more than just a dark shade at the outer rim. it also impacts contrast at the outer rim and when you are a little less lucky, image sharpness, astigmatism and other lens defects will produce increasingly pronounced randomness in the pixel signal at the outer rim.

> Nerd Alert: this is where some physics major or other knowledgeable communications highwaymanly individual will jump out of the rose bushes, blocking your way and start exhorting that that last statement right there is *so very wrong* and *utterly false*! Yes, buddy, you are correct. Lens distortions in camera equipment do not add randomness to the light signal. When constructed and/or fabricated less than ideally, they merely cause all sorts of obnoxious light path distortions, which, *theoretically*, may be corrected (by better construction, fabrication or maybe even *in post*). Indeed, nothing *random* or *noisy* there, my good man. (Strangely no woman got involved, *ever*, or at least such is the tally after decades of empirical data gathering by yours truly. So very strange indeed. -- Incidentally, I'ld love to hear about any data that's counter to this observed fact.)
> Regrettable though, our *image sensor* and *image file format* suffers from *practical limits*, such as sensitivity limits (in one extremum: local over- and under-exposure, f.e.) and quantization aspects: almost all image formats store greyscale values in a byte per pixel, therefor delivering a range of only 256 individual intensity values to choose from, while the color ones do RGB in 1+1+1=3 bytes for a whopping 24 million or there-abouts colors, *woo-hoo*! Which is far too few and way too small a range to properly measure the incoming light values when your aim is to observe them properly and compensate for any deviations that might have been added on along the way. 
> Thanks to the quantization effects at both the sensor level and the image file format level (which is why photographers like to work with RAW image files when they *can*) we are faced with severely deteriorated accuracy and resolution of measurement *in actual practice*. Consequently, when we apply those image corrections necessary to compensate for the physical aspects introduced by our camera lenses, etc., we cannot apply them to the actual photons but the byte (word?) intensity values instead, resulting in the *observation* that our *sensor noise* is becoming a major factor for some pixels as those receive only little light (e.g. due to vignetting) and thus further reduced incoming *senseable* light range and precision. In short: the noise injected into our source signal due to sensor noise and other aspects has varying prominence across the image area depending on equipment used (also do note that we live in air, which transports particles a.k.a. dust, which randomly obstruct and thus impacts our light path and thus effs up our moment of photography action); any corrections/compensation applied to the resulting image, if at all possible, will therefor propagate an amplified noise factor for image areas where light levels have been impacted more significantly then elsewhere in the picture. Which means: you'll end up with (locally) *more noise* in your *compensated/corrected* image signal: "*increasingly pronounced randomness in the pixel signal*". 
> The defense rests. Please return to your rose bush, thank you!

plenty hard to deal with, reckon with a customized compensation approach.

can we detect this sort of thing?

